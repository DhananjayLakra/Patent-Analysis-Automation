{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Patent technology domain analysis using NLP\n",
        "This program automates the patent analysis process for large batches (10,000+) of patents by allowing users to extract data from Google Patents. By extracting insights such as the Title, Abstract, and frequently occurring keywords in the patent text, users can quickly deduce the technological domain of each patent.\n",
        "\n",
        "The program significantly reduces the time spent on manual patent page reviews, especially when dealing with large patent portfolios. This time-saving effect becomes even more pronounced as the size of the patent batch increases."
      ],
      "metadata": {
        "id": "8G2hmM5erf8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the required modules"
      ],
      "metadata": {
        "id": "kM3TKk4sq3_p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNW7TwuwqtCX",
        "outputId": "18abe665-c2fc-45da-90ab-994814615c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Install required libraries and download NLTK data\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Ensure NLTK data is downloaded\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt', raise_on_error=True)\n",
        "nltk.download('stopwords', raise_on_error=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Patent page content\n",
        "This function will fetch the patent content from Google Patent's database"
      ],
      "metadata": {
        "id": "Ez2Lb57XrRCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_patent_page(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        raise Exception(f\"Failed to fetch page: {response.status_code}\")"
      ],
      "metadata": {
        "id": "G7VRjXMSq9rB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Claim 1 and text from Patent page\n",
        "This function is responsible for extracting the first claim from the patent text"
      ],
      "metadata": {
        "id": "fPhMDUl7vFrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_claim_abstract_and_text(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Extracting Claim 1\n",
        "    first_claim_div = soup.find('div', id='CLM-00001')  # Look for the div with id=\"CLM-00001\"\n",
        "    first_claim = ''\n",
        "    if first_claim_div:\n",
        "        # Combine all text within this div and its children\n",
        "        first_claim = ' '.join(first_claim_div.stripped_strings)\n",
        "\n",
        "    # Extracting the Abstract\n",
        "    abstract_section = soup.find('section', itemprop='abstract')\n",
        "    abstract = ''\n",
        "    if abstract_section:\n",
        "        abstract_div = abstract_section.find('div', itemprop='content') or abstract_section.find('abstract')\n",
        "        if abstract_div:\n",
        "            abstract = abstract_div.get_text(separator=' ', strip=True)\n",
        "\n",
        "    # Extracting text from abstract, claims, and description\n",
        "    abstract_text = soup.find('div', class_='abstract')\n",
        "    description = soup.find('section', class_='description')\n",
        "\n",
        "    text = ''\n",
        "    if abstract_text:\n",
        "        text += abstract_text.get_text(separator=' ', strip=True) + ' '\n",
        "    if description:\n",
        "        text += description.get_text(separator=' ', strip=True) + ' '\n",
        "\n",
        "    return first_claim, abstract, text"
      ],
      "metadata": {
        "id": "HbLilCqbvCks"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning and tokenizing the text"
      ],
      "metadata": {
        "id": "4sXMTr9OvXmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean and tokenize the text\n",
        "def clean_and_tokenize_text(text):\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
        "    words = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return words"
      ],
      "metadata": {
        "id": "nsQ_g4YcvS3k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Bigrams (2-Word Keywords) and Trigrams (3-word keywords) from the patent text\n",
        "This function will extract bigrams and trigrams from the patent text. I chose bigrams and trigrams instead of one-word keywords as one-word keywords may contain junk values; some words may have a high frequency but don't necessarily provide any insight to the patent's technology domain. For example, the word \"user\" may appear many times in a patent's text, but by itself it is meaningless.\n"
      ],
      "metadata": {
        "id": "ILKlwvBvwETp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bigrams_and_trigrams(words, num_keywords=10):\n",
        "    bigrams = ngrams(words, 2)\n",
        "    trigrams = ngrams(words, 3)\n",
        "\n",
        "    #get the frequency count for the bigrams and trigrams\n",
        "    bigram_freq = Counter(bigrams)\n",
        "    trigram_freq = Counter(trigrams)\n",
        "\n",
        "    #get the most commonly occuring bigrams and trigrams\n",
        "    common_bigrams = bigram_freq.most_common(num_keywords)\n",
        "    common_trigrams = trigram_freq.most_common(num_keywords)\n",
        "\n",
        "    bigram_keywords = [' '.join(bigram) for bigram, _ in common_bigrams]\n",
        "    trigram_keywords = [' '.join(trigram) for trigram, _ in common_trigrams]\n",
        "\n",
        "    return bigram_keywords, trigram_keywords"
      ],
      "metadata": {
        "id": "dWOA66GKvw1T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Patents from an Excel File"
      ],
      "metadata": {
        "id": "GwgAAkolzXYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_patents_from_excel(file_path, patent_column, output_file):\n",
        "    # Read the Excel file\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Add new columns for claim 1, abstract, bigrams, and trigrams\n",
        "    df['Claim 1'] = ''\n",
        "    df['Abstract'] = ''\n",
        "    df['Bigrams'] = ''\n",
        "    df['Trigrams'] = ''\n",
        "\n",
        "    # Iterate through the patents\n",
        "    for index, row in df.iterrows():\n",
        "        patent_number = row[patent_column]\n",
        "        if pd.isna(patent_number):\n",
        "            continue\n",
        "\n",
        "        # Construct the patent URL\n",
        "        url = f\"https://patents.google.com/patent/{patent_number.strip()}\"\n",
        "\n",
        "        try:\n",
        "            # Fetch and process the patent page\n",
        "            html_content = fetch_patent_page(url)\n",
        "            claim_1, abstract, text = extract_claim_abstract_and_text(html_content)\n",
        "            words = clean_and_tokenize_text(text)\n",
        "\n",
        "            # Extract bigrams and trigrams\n",
        "            bigrams, trigrams = extract_bigrams_and_trigrams(words)\n",
        "\n",
        "            # Update the DataFrame with claim 1, abstract, bigrams, and trigrams\n",
        "            df.at[index, 'Claim 1'] = claim_1\n",
        "            df.at[index, 'Abstract'] = abstract\n",
        "            df.at[index, 'Bigrams'] = ', '.join(bigrams)\n",
        "            df.at[index, 'Trigrams'] = ', '.join(trigrams)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing patent {patent_number}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Save the updated DataFrame back to Excel\n",
        "    df.to_excel(output_file, index=False)\n",
        "    print(f\"Processing complete. Results saved to {output_file}\")"
      ],
      "metadata": {
        "id": "iGVpk6VbzQ28"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading Excel file and calling the process Patents function\n",
        "\n"
      ],
      "metadata": {
        "id": "9WTw8AEs0cyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload the Excel file\n",
        "uploaded = files.upload()\n",
        "input_excel = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "\n",
        "# Output file\n",
        "output_excel = 'processed_patents.xlsx'\n",
        "patent_column_name = 'Patent Number'  # Column name containing patent numbers\n",
        "\n",
        "# Process the patents\n",
        "process_patents_from_excel(input_excel, patent_column_name, output_excel)\n",
        "\n",
        "#Download the output excel\n",
        "files.download(output_excel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "CNsLEIRJ0M-K",
        "outputId": "f71b2d81-26f1-4884-cc5d-36ffb85959f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-56e8df08-29f1-42c3-a1e4-4aa750bc684d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-56e8df08-29f1-42c3-a1e4-4aa750bc684d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving patents.xlsx to patents.xlsx\n",
            "Processing complete. Results saved to processed_patents.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_108aa20a-4af9-4a69-ac40-5a02c9fa5fcc\", \"processed_patents.xlsx\", 8100)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}